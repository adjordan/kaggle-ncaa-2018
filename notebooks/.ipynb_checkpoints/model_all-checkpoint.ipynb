{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, ExtraTreesRegressor, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "root = \"/home/austin/Github/kaggle-ncaa-2018/\"\n",
    "\n",
    "data = pd.read_csv(root + \"derived_data/Master.csv\")\n",
    "matchups = pd.read_csv(\"/home/austin/Github/DataFiles/TourneyWinratesBySeed.csv\")\n",
    "tour_ratios = pd.read_csv(root + \"derived_data/ratios/NCAATourneyDetailedResultsRatios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = range(2003, 2018)\n",
    "\n",
    "all_columns = data.columns.tolist()\n",
    "non_stats_columns = [\"Season\", \"TeamID\", \"Seed\", \"Elo\"]#, \"BPI\", \"Predictor_Score\"]\n",
    "stats_columns = [c for c in all_columns if c not in non_stats_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put all data in a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourney_games = tour_ratios.loc[tour_ratios[\"Season\"].isin(seasons)]\n",
    "tourney_games = tourney_games.reset_index(drop=True)\n",
    "extra_cols = [\"NumTeamSeed\", \"DenTeamSeed\", \"NumTeamElo\", \"DenTeamElo\", \"HistWinPct\"]\n",
    "\n",
    "pred_data = pd.DataFrame(index=range(tourney_games.shape[0]), columns= [\"Season\"] + stats_columns + extra_cols + [\"NumTeamWon\"])\n",
    "pred_data.loc[:,\"NumTeamWon\"] = np.ones(tourney_games.shape[0])\n",
    "index = 0\n",
    "for i in range(len(seasons)):\n",
    "    season = seasons[i]\n",
    "    tourney_games_for_season = tourney_games.loc[tourney_games[\"Season\"] == season].reset_index()\n",
    "    for j, row in tourney_games_for_season.iterrows():\n",
    "        pred_data.loc[index, \"Season\"] = season\n",
    "        teamA_id = tourney_games_for_season.at[j, \"WTeamID\"]\n",
    "        teamB_id = tourney_games_for_season.at[j, \"LTeamID\"]\n",
    "        \n",
    "        teamA_seed = data.loc[(data[\"TeamID\"] == teamA_id) & (data[\"Season\"] == season)].reset_index(drop=True).loc[0, \"Seed\"]\n",
    "        teamB_seed = data.loc[(data[\"TeamID\"] == teamB_id) & (data[\"Season\"] == season)].reset_index(drop=True).loc[0, \"Seed\"]\n",
    "        \n",
    "        teamA_elo = data.loc[(data[\"TeamID\"] == teamA_id) & (data[\"Season\"] == season)].reset_index(drop=True).loc[0, \"Elo\"]\n",
    "        teamB_elo = data.loc[(data[\"TeamID\"] == teamB_id) & (data[\"Season\"] == season)].reset_index(drop=True).loc[0, \"Elo\"]\n",
    "        \n",
    "        teamA_stats = data.loc[(data[\"TeamID\"] == teamA_id) & (data[\"Season\"] == season), stats_columns].as_matrix()\n",
    "        teamB_stats = data.loc[(data[\"TeamID\"] == teamB_id) & (data[\"Season\"] == season), stats_columns].as_matrix()\n",
    "        \n",
    "        r = random.random()\n",
    "        \n",
    "        if r > 0.5:\n",
    "            pred_data.at[index, stats_columns] = (teamA_stats / teamB_stats).ravel()\n",
    "            pred_data.at[index, \"NumTeamSeed\"] = teamA_seed\n",
    "            pred_data.at[index, \"DenTeamSeed\"] = teamB_seed\n",
    "            pred_data.at[index, \"NumTeamElo\"] = teamA_elo\n",
    "            pred_data.at[index, \"DenTeamElo\"] = teamB_elo\n",
    "            pred_data.at[index, \"HistWinPct\"] = matchups[(matchups[\"WinSeed\"] == teamA_seed) & (matchups[\"LoseSeed\"] == teamB_seed)][\"1985\"]\n",
    "        else:\n",
    "            pred_data.at[index, stats_columns] = (teamB_stats / teamA_stats).ravel()\n",
    "            pred_data.at[index, \"NumTeamSeed\"] = teamB_seed\n",
    "            pred_data.at[index, \"DenTeamSeed\"] = teamA_seed\n",
    "            pred_data.at[index, \"NumTeamElo\"] = teamB_elo\n",
    "            pred_data.at[index, \"DenTeamElo\"] = teamA_elo\n",
    "            pred_data.at[index, \"HistWinPct\"] = matchups[(matchups[\"WinSeed\"] == teamB_seed) & (matchups[\"LoseSeed\"] == teamA_seed)][\"1985\"]\n",
    "            pred_data.at[index, \"NumTeamWon\"] = 0\n",
    "        \n",
    "        index += 1\n",
    "\n",
    "pred_data = pred_data.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select which stats to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FGM', 'PIE', 'TURNOVER_RATE', 'OFF_REB_PCT', 'OFF_EFF', 'DEF_EFF', 'WINPCT', 'NumTeamSeed', 'DenTeamSeed', 'NumTeamElo', 'DenTeamElo', 'HistWinPct']\n"
     ]
    }
   ],
   "source": [
    "all_train_columns = stats_columns + extra_cols\n",
    "# train_columns_to_drop = [\"FTM\", \"FGA\", \"TS%\", \"eFG%\", \"4FACTOR\", \"FG_PCT\", \"FT/FGA\", \"3PAr\", \"STL%\", \"Ast\",\n",
    "#                          \"ASSIST_RATIO\", \"DR\", \"FGA3\", \"DEF_REB_PCT\"]\n",
    "\n",
    "train_columns_to_drop = [\"FGM3\", \"FTM\", \"FGA3\", \"FTA\", \"4FACTOR\", \"DEF_REB_PCT\", \"FT_PCT\", \"DR\", \"ASSIST_RATIO\",\n",
    "                         \"Stl\", \"FG_PCT\", \"FGA\", \"PF\", \"FT_RATE\", \"OR\", \"Ast\", \"TO\", \"Blk\"]\n",
    "\n",
    "train_columns = [c for c in all_train_columns if c not in train_columns_to_drop]\n",
    "print(train_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(914, 12)\n",
      "(914,)\n",
      "(67, 12)\n",
      "(67,)\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "seasons_test = [2017]\n",
    "seasons_train = [season for season in seasons if season not in seasons_test]\n",
    "\n",
    "train_x = pred_data.loc[pred_data[\"Season\"].isin(seasons_train)][train_columns].as_matrix()\n",
    "train_y = pred_data.loc[pred_data[\"Season\"].isin(seasons_train)][\"NumTeamWon\"].as_matrix()\n",
    "test_x = pred_data.loc[pred_data[\"Season\"].isin(seasons_test)][train_columns].as_matrix()\n",
    "test_y = pred_data.loc[pred_data[\"Season\"].isin(seasons_test)][\"NumTeamWon\"].as_matrix()\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "print(len(train_columns))\n",
    "\n",
    "# from keras.utils import to_categorical\n",
    "# # train_y = to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'tol': [0.0001, 0.001, 0.01, 0.1], 'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10],\n",
    "              'tol': [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "              }\n",
    "\n",
    "logReg = GridSearchCV(LogisticRegression(), parameters, cv=10)\n",
    "\n",
    "logReg.fit(train_x, train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Test:   0.746268656716418\n",
      "Log Loss, Test:   0.5002241648313955\n"
     ]
    }
   ],
   "source": [
    "preds_train = np.array(logReg.predict_proba(train_x))\n",
    "preds_test_lr = np.array(logReg.predict_proba(test_x))[:,1]\n",
    "\n",
    "# print(preds_test)\n",
    "# print(test_y)\n",
    "\n",
    "# threshold = .1\n",
    "\n",
    "# preds_test_lr[preds_test_lr > 1 - threshold] = 1\n",
    "# preds_test_lr[preds_test_lr < threshold] = 0\n",
    "\n",
    "# print(logReg.best_params_)\n",
    "\n",
    "# print(\"Accuracy, Train: \", accuracy_score(train_y, preds_train > 0.5))\n",
    "# print(\"Log Loss, Train: \", log_loss(train_y, preds_train))\n",
    "# print(\"\")\n",
    "print(\"Accuracy, Test:  \", accuracy_score(test_y, preds_test_lr > 0.5))\n",
    "print(\"Log Loss, Test:  \", log_loss(test_y, preds_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': array([ 2,  6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46]), 'min_samples_leaf': array([ 1,  5,  9, 13, 17, 21]), 'max_features': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(log_loss), verbose=0)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "parameters = {'max_features': np.arange(1,12,1),\n",
    "              'min_samples_split': np.arange(2,50,4),\n",
    "              'min_samples_leaf': np.arange(1,25,4)\n",
    "              }\n",
    "\n",
    "RF = GridSearchCV(RandomForestRegressor(n_estimators=1000, n_jobs=-1, random_state=0), parameters,\n",
    "                    cv=10, scoring=make_scorer(log_loss))\n",
    "# RF = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=0, max_features=4, min_samples_leaf=40)\n",
    "\n",
    "# clf = ExtraTreesRegressor(n_estimators=1000, max_features=1, n_jobs=-1)\n",
    "# clf = LogisticRegression(n_jobs=-1)\n",
    "RF.fit(train_x, train_y.ravel())\n",
    "# print(\"OOB Score: \", clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 11}\n",
      "Accuracy, Test:   0.7164179104477612\n",
      "Log Loss, Test:   0.5478577232123406\n"
     ]
    }
   ],
   "source": [
    "print(RF.best_params_)\n",
    "\n",
    "preds_train = RF.predict(train_x)\n",
    "# preds_test_rf = RF.predict_proba(test_x)[:,1]\n",
    "preds_test_rf = RF.predict(test_x)\n",
    "\n",
    "# threshold = .1\n",
    "# preds_test_rf[preds_test_rf > 1 - threshold] = 1\n",
    "# preds_test_rf[preds_test_rf < threshold] = 0\n",
    "\n",
    "# print(\"Accuracy, Train: \", accuracy_score(train_y, preds_train > 0.5))\n",
    "# print(\"Log Loss, Train: \", log_loss(train_y, preds_train))\n",
    "# print(\"\")\n",
    "print(\"Accuracy, Test:  \", accuracy_score(test_y, preds_test_rf > 0.5))\n",
    "print(\"Log Loss, Test:  \", log_loss(test_y, preds_test_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFF_REB_PCT : 0.014324658861801336\n",
      "TURNOVER_RATE : 0.01660118746435672\n",
      "FGM : 0.018933310687614825\n",
      "DEF_EFF : 0.02105622548257219\n",
      "OFF_EFF : 0.031947183830035475\n",
      "WINPCT : 0.03345639859970109\n",
      "DenTeamSeed : 0.07069475619186985\n",
      "DenTeamElo : 0.07175865647977786\n",
      "PIE : 0.0737976526888745\n",
      "NumTeamSeed : 0.09452458727097553\n",
      "NumTeamElo : 0.17270712944538316\n",
      "HistWinPct : 0.38019825299703836\n"
     ]
    }
   ],
   "source": [
    "variables = train_columns\n",
    "feature_importance = RF.feature_importances_\n",
    "\n",
    "feature_importance, variables = (list(t) for t in zip(*sorted(zip(feature_importance, variables))))\n",
    "\n",
    "for i in range(len(feature_importance)):\n",
    "    print(variables[i], \":\", feature_importance[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter = VotingClassifier(estimators=[('lr', logReg), ('rf', RF)], voting='soft')\n",
    "voter.fit(train_x, train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Test:   0.7611940298507462\n",
      "Log Loss, Test:   0.4994045865095755\n"
     ]
    }
   ],
   "source": [
    "preds_test = voter.predict_proba(test_x)[:,1]\n",
    "threshold = .12\n",
    "preds_test[preds_test > 1 - threshold] = 1\n",
    "preds_test[preds_test < threshold] = 0\n",
    "print(\"Accuracy, Test:  \", accuracy_score(test_y, preds_test > 0.5))\n",
    "print(\"Log Loss, Test:  \", log_loss(test_y, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss, Test:   0.5118223012088069\n"
     ]
    }
   ],
   "source": [
    "preds = (preds_test_lr + preds_test_rf) / 2\n",
    "print(\"Log Loss, Test:  \", log_loss(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
