{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant data files\n",
    "reg_ratios = pd.read_csv(\"RegularSeasonDetailedResultsRatios.csv\")\n",
    "tour_ratios = pd.read_csv(\"NCAATourneyDetailedResultsRatios.csv\")\n",
    "reg_season_avgs = pd.read_csv(\"RegularSeasonAverageRatios.csv\")\n",
    "\n",
    "# List of all columns in the datasets\n",
    "# all_cols = reg_ratios.columns.tolist()\n",
    "all_cols = [\"Season\", \"WTeamID\", \"WScore\", \"LTeamID\", \"LScore\", \"NumTeamWon\", \"Loc\",\n",
    "                 \"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"ORR\", \"DRR\", \"AstR\",\n",
    "                 \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]\n",
    "\n",
    "# Columns that won't be used in the dataset\n",
    "cols_to_drop = [\"Season\", \"WTeamID\", \"WScore\", \"LTeamID\", \"LScore\", \"NumTeamWon\", \"Loc\"]\n",
    "\n",
    "# Columns that will be used in the dataset\n",
    "stats_columns = [item for item in all_cols if item not in cols_to_drop]\n",
    "\n",
    "# Seasons to look at\n",
    "seasons = [2017]\n",
    "\n",
    "# Specify what to use as the training data\n",
    "train_data = reg_ratios\n",
    "\n",
    "# Get all of the training data for the given years\n",
    "train_x = train_data.loc[reg_ratios[\"Season\"].isin(seasons)].drop(labels=cols_to_drop, axis=1).as_matrix()\n",
    "train_y = train_data.loc[reg_ratios[\"Season\"].isin(seasons)][\"NumTeamWon\"].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X:  (5395, 13)\n",
      "Train Y:  (5395,)\n",
      "Test X:   (67, 13)\n",
      "Test Y:   (67,)\n"
     ]
    }
   ],
   "source": [
    "tourney_games = tour_ratios.loc[tour_ratios[\"Season\"].isin(seasons)]\n",
    "tourney_games = tourney_games.reset_index(drop=True)\n",
    "\n",
    "test_x = pd.DataFrame(index=range(tourney_games.shape[0]), columns=stats_columns)\n",
    "test_y = np.ones(67*len(seasons))\n",
    "for i in range(len(seasons)):\n",
    "    season = seasons[i]\n",
    "    tourney_games_for_season = tourney_games.loc[tourney_games[\"Season\"] == season]\n",
    "    for j, row in tourney_games_for_season.iterrows():\n",
    "        index = i * 67 + j\n",
    "        teamA_id = tourney_games_for_season.at[j, \"WTeamID\"]\n",
    "        teamB_id = tourney_games_for_season.at[j, \"LTeamID\"]\n",
    "        teamA_stats = reg_season_avgs.loc[(reg_season_avgs[\"TeamID\"] == teamA_id) & (reg_season_avgs[\"Season\"] == season), stats_columns].as_matrix()\n",
    "        teamB_stats = reg_season_avgs.loc[(reg_season_avgs[\"TeamID\"] == teamB_id) & (reg_season_avgs[\"Season\"] == season), stats_columns].as_matrix()\n",
    "        r = random.random()\n",
    "        if r > 0.5:\n",
    "            test_x.loc[index, stats_columns] = teamA_stats / teamB_stats\n",
    "        else:\n",
    "            test_x.loc[index, stats_columns] = teamB_stats / teamA_stats\n",
    "            test_y[j] = 0\n",
    "    \n",
    "test_x = test_x.as_matrix()\n",
    "print(\"Train X: \", train_x.shape)\n",
    "print(\"Train Y: \", train_y.shape)\n",
    "print(\"Test X:  \", test_x.shape)\n",
    "print(\"Test Y:  \", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=50,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=5000, n_jobs=-1, oob_score=False,\n",
       "           random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestRegressor(n_estimators=5000, oob_score=False, max_features=1, min_samples_leaf=50, n_jobs=-1)\n",
    "clf.fit(train_x, train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Train:  0.9490268767377201\n",
      "Log Loss, Train:  0.32303054403482695\n",
      "\n",
      "Accuracy, Test:   0.6865671641791045\n",
      "Log Loss, Test:   0.5978310327542643\n"
     ]
    }
   ],
   "source": [
    "preds_train = clf.predict(train_x)\n",
    "preds_test = clf.predict(test_x)\n",
    "\n",
    "print(\"Accuracy, Train: \", accuracy_score(train_y, preds_train > 0.5))\n",
    "print(\"Log Loss, Train: \", log_loss(train_y, preds_train))\n",
    "print(\"\")\n",
    "print(\"Accuracy, Test:  \", accuracy_score(test_y, preds_test > 0.5))\n",
    "print(\"Log Loss, Test:  \", log_loss(test_y, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGMR : 0.20654888069483596\n",
      "FGAR : 0.020037413336939577\n",
      "FGMR3 : 0.05914881017111136\n",
      "FGAR3 : 0.013465290749479218\n",
      "FTMR : 0.09872771193889555\n",
      "FTAR : 0.08368906068316485\n",
      "ORR : 0.006865472212006444\n",
      "DRR : 0.1858764377111324\n",
      "AstR : 0.1369655149636822\n",
      "TOR : 0.039138604276543046\n",
      "StlR : 0.03183936615180908\n",
      "BlkR : 0.039642835300210816\n",
      "PFR : 0.07805460181018832\n"
     ]
    }
   ],
   "source": [
    "variables = stats_columns\n",
    "feature_importance = clf.feature_importances_\n",
    "for i in range(len(feature_importance)):\n",
    "    print(variables[i], \":\", feature_importance[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
