{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New model:\n",
    "# Train on all regular season data, including teamID\n",
    "# Predict based on team's last X games\n",
    "games_to_use = 20\n",
    "import math\n",
    "\n",
    "reg_ratios = pd.read_csv(\"RegularSeasonDetailedResultsRatios.csv\")\n",
    "tour_ratios = pd.read_csv(\"NCAATourneyDetailedResultsRatios.csv\")\n",
    "all_cols = [\"Season\", \"DayNum\", \"WTeamID\", \"WScore\", \"LTeamID\", \"LScore\", \"NumTeamWon\", \"Loc\",\n",
    "                 \"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"ORR\", \"DRR\", \"AstR\",\n",
    "                 \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]\n",
    "\n",
    "# Add day numbers to regular season games\n",
    "regular_season_data = pd.read_csv(\"RegularSeasonDetailedResults.csv\")\n",
    "reg_ratios[\"DayNum\"] = regular_season_data[\"DayNum\"]\n",
    "reg_ratios[\"Season\"] = reg_ratios[\"Season\"].astype(int)\n",
    "# print(reg_ratios.loc[reg_ratios[\"Season\"] == 2017])\n",
    "# print(reg_ratios)\n",
    "\n",
    "# Get train data: all regular season games\n",
    "# cols_to_drop = [\"Season\", \"DayNum\", \"WScore\", \"WTeamID\", \"LScore\", \"LTeamID\", \"NumTeamWon\", \"Loc\"]\n",
    "cols_to_drop = [\"Season\", \"DayNum\", \"WScore\", \"LScore\", \"NumTeamWon\", \"Loc\", \"WTeamID\", \"LTeamID\"]\n",
    "stats_cols = [item for item in all_cols if item not in cols_to_drop]\n",
    "\n",
    "train_data = reg_ratios\n",
    "train_x = reg_ratios.loc[reg_ratios[\"Season\"] == 2017].drop(labels=cols_to_drop, axis=1).as_matrix()\n",
    "train_y = reg_ratios.loc[reg_ratios[\"Season\"] == 2017][\"NumTeamWon\"].as_matrix()\n",
    "\n",
    "# Get all team IDs from the tournament\n",
    "tour_avg_cols = [\"TeamID\"] + stats_cols\n",
    "team_ids = pd.unique(tour_ratios.loc[tour_ratios[\"Season\"] == 2017, [\"WTeamID\", \"LTeamID\"]].values.ravel('K'))\n",
    "tour_avgs = pd.DataFrame(index=range(team_ids.shape[0]), columns=tour_avg_cols)\n",
    "tour_avgs.loc[:,\"TeamID\"] = team_ids\n",
    "# print(test_x)\n",
    "\n",
    "for team_id in team_ids:\n",
    "    games_all = reg_ratios.loc[(reg_ratios[\"WTeamID\"] == team_id) | (reg_ratios[\"LTeamID\"] == team_id)]\n",
    "    games = games_all.loc[games_all[\"Season\"] == 2017]\n",
    "    games.reset_index(inplace=True, drop=True)\n",
    "    games_stats = games.loc[:, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"ORR\", \"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]]\n",
    "    for i, row in games.iterrows():\n",
    "        if ((team_id == row[\"WTeamID\"]) & (row[\"NumTeamWon\"] == 0)) | ((team_id == row[\"LTeamID\"]) & (row[\"NumTeamWon\"] == 1)):\n",
    "            games_stats.iloc[i] = games_stats.iloc[i].apply(np.reciprocal)\n",
    "#             if math.isinf(games_stats.at[i,\"Loc\"]):\n",
    "#                 games_stats.loc[i,\"Loc\"] = 0\n",
    "    \n",
    "    tour_avgs.loc[tour_avgs[\"TeamID\"] == team_id, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"ORR\", \"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]] = games_stats.mean(axis=0).ravel()\n",
    "    \n",
    "tour_avgs = tour_avgs.set_index(\"TeamID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test_x_columns = [item for item in all_cols if item not in cols_to_drop]\n",
    "# print(test_x_columns)\n",
    "\n",
    "tourney_games_2017 = tour_ratios.loc[tour_ratios[\"Season\"] == 2017]\n",
    "tourney_games_2017 = tourney_games_2017.reset_index(drop=True)\n",
    "# print(tourney_games_2017.shape)\n",
    "test_x = pd.DataFrame(index=range(tourney_games_2017.shape[0]), columns=test_x_columns)\n",
    "test_y = np.ones(67)\n",
    "for i, row in tourney_games_2017.iterrows():\n",
    "    teamA_id = tourney_games_2017.at[i, \"WTeamID\"]\n",
    "    teamB_id = tourney_games_2017.at[i, \"LTeamID\"]\n",
    "    teamA_stats = tour_avgs.loc[teamA_id, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"ORR\", \"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]].as_matrix()\n",
    "    teamB_stats = tour_avgs.loc[teamB_id, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"ORR\", \"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]].as_matrix()\n",
    "    r = random.random()\n",
    "    if r > 0.5:\n",
    "#         test_x[\"WTeamID\"] = teamA_id\n",
    "#         test_x[\"LTeamID\"] = teamB_id\n",
    "#         test_x[\"Loc\"] = 0\n",
    "        test_x.loc[i, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"ORR\", \"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]] = teamA_stats / teamB_stats\n",
    "    else:\n",
    "#         test_x[\"WTeamID\"] = teamB_id\n",
    "#         test_x[\"LTeamID\"] = teamA_id\n",
    "#         test_x[\"Loc\"] = 0\n",
    "        test_x.loc[i, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"ORR\", \"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]] = teamB_stats / teamA_stats\n",
    "        test_y[i] = 0\n",
    "    \n",
    "# print(test_x)\n",
    "test_x = test_x.as_matrix()\n",
    "# print(train_x.shape)\n",
    "# print(train_y.shape)\n",
    "# print(test_x.shape)\n",
    "# print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oob score: {} 0.6224520751701116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# num_splits = 10\n",
    "# ll_best = 1000\n",
    "# num_features_best = 1\n",
    "# kf = KFold(n_splits=num_splits)\n",
    "# for num_features_to_use in range(1, 17):\n",
    "#     ll_feature_count = 0\n",
    "#     for train, test in kf.split(train_x):\n",
    "#         clf2 = RandomForestRegressor(n_estimators=5000, oob_score=True, max_features=num_features_to_use)\n",
    "#         clf2.fit(train_x[train], train_y[train].ravel())\n",
    "#         preds = clf2.predict(train_x[test])\n",
    "#         ll_feature_count = log_loss(train_y[test], preds) / num_splits\n",
    "    \n",
    "#     if ll_feature_count < ll_best:\n",
    "#         ll_best = ll_feature_count\n",
    "#         num_features_best = num_features_to_use\n",
    "\n",
    "# print(\"Best number of features to use: {}\", num_features_best)\n",
    "# print(\"Log loss achieved: {}\", ll_best)\n",
    "\n",
    "clf2 = RandomForestRegressor(n_estimators=5000, oob_score=True, max_features=1, min_samples_leaf=50, n_jobs=-1)\n",
    "clf2.fit(train_x, train_y.ravel())\n",
    "print(\"oob score: {}\", clf2.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      "Accuracy score 0.6716417910447762\n",
      "[0.44583549 0.30040483 0.1773321  0.33842489 0.26227531 0.57740319\n",
      " 0.62921502 0.7565605  0.07340146 0.60153899 0.55710823 0.48177796\n",
      " 0.56015652 0.34411795 0.15367603 0.88442564 0.28223433 0.62536213\n",
      " 0.79748608 0.55143583 0.34645554 0.55357958 0.82000923 0.1859739\n",
      " 0.24782824 0.15475341 0.22137542 0.25937001 0.66301079 0.32633523\n",
      " 0.09269351 0.56937315 0.1827745  0.16570045 0.76596859 0.16696443\n",
      " 0.28616858 0.33966455 0.50890401 0.05639514 0.74251453 0.62852676\n",
      " 0.63271566 0.72889858 0.60656389 0.7826614  0.25253016 0.55042769\n",
      " 0.81258514 0.82598866 0.58297693 0.53386102 0.83939226 0.21815672\n",
      " 0.64460836 0.14080768 0.55217879 0.51908722 0.76079719 0.56876295\n",
      " 0.0687683  0.74478537 0.56379123 0.33690649 0.1441361  0.47561667\n",
      " 0.16077684]\n",
      "[0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      "Log loss 0.6033589800074204\n"
     ]
    }
   ],
   "source": [
    "print(test_y)\n",
    "preds = clf2.predict(test_x)\n",
    "print(\"Accuracy score\", accuracy_score(test_y, preds > 0.5))\n",
    "print(preds)\n",
    "print(test_y)\n",
    "print(\"Log loss\", log_loss(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
