{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ratios = pd.read_csv(\"RegularSeasonDetailedResultsRatios.csv\")\n",
    "cols_to_drop = [\"Season\", \"DayNum\", \"WTeamID\", \"WScore\", \"LTeamID\", \"LScore\", \"NumTeamWon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rows for 2017 season and drop irrelevant variables\n",
    "test_data = reg_ratios.loc[reg_ratios['Season'] == 2017]\n",
    "test_x = test_data.drop(columns=cols_to_drop, axis=1).as_matrix()\n",
    "test_y = test_data[\"NumTeamWon\"].as_matrix()\n",
    "\n",
    "# Get rows for all other seasons, drop irrelevant variables\n",
    "train_data = reg_ratios[reg_ratios.Season != 2017]\n",
    "train_x = train_data.drop(labels=cols_to_drop, axis=1).as_matrix()\n",
    "train_y = train_data[\"NumTeamWon\"].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "clf = RandomForestRegressor(n_estimators=100)\n",
    "clf.fit(train_x, train_y.ravel())\n",
    "# print(\"Out-of-bag score: {}\".format(clf.oob_score_))\n",
    "# acc = clf.score(test_x, test_y.ravel())\n",
    "# print(\"Test accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "preds = clf.predict(test_x)\n",
    "print(preds.shape)\n",
    "print(test_y.shape)\n",
    "print(\"Accuracy score\", accuracy_score(test_y, preds > 0.5))\n",
    "print(\"Log loss\", log_loss(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New model:\n",
    "# Train on all regular season data, including teamID\n",
    "# Predict based on team's last X games\n",
    "games_to_use = 20\n",
    "import math\n",
    "\n",
    "reg_ratios = pd.read_csv(\"RegularSeasonDetailedResultsRatios.csv\")\n",
    "tour_ratios = pd.read_csv(\"NCAATourneyDetailedResultsRatios.csv\")\n",
    "all_cols = [\"Season\", \"DayNum\", \"WTeamID\", \"WScore\", \"LTeamID\", \"LScore\", \"NumTeamWon\", \"Loc\",\n",
    "                 \"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"ORR\", \"DRR\", \"AstR\",\n",
    "                 \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]\n",
    "\n",
    "# Add day numbers to regular season games\n",
    "regular_season_data = pd.read_csv(\"RegularSeasonDetailedResults.csv\")\n",
    "reg_ratios[\"DayNum\"] = regular_season_data[\"DayNum\"]\n",
    "reg_ratios[\"Season\"] = reg_ratios[\"Season\"].astype(int)\n",
    "# print(reg_ratios.loc[reg_ratios[\"Season\"] == 2017])\n",
    "# print(reg_ratios)\n",
    "\n",
    "# Get train data: all regular season games\n",
    "# cols_to_drop = [\"Season\", \"DayNum\", \"WScore\", \"WTeamID\", \"LScore\", \"LTeamID\", \"NumTeamWon\", \"Loc\"]\n",
    "cols_to_drop = [\"Season\", \"DayNum\", \"WScore\", \"LScore\", \"NumTeamWon\", \"Loc\", \"WTeamID\", \"LTeamID\", \"ORR\"]\n",
    "\n",
    "train_data = reg_ratios\n",
    "train_x = reg_ratios.loc[reg_ratios[\"Season\"] == 2015].drop(labels=cols_to_drop, axis=1).as_matrix()\n",
    "train_y = reg_ratios.loc[reg_ratios[\"Season\"] == 2015][\"NumTeamWon\"].as_matrix()\n",
    "\n",
    "# Get all team IDs from the tournament\n",
    "tour_avg_cols = [\"TeamID\", \"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\",\"DRR\", \"AstR\",\n",
    "                 \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]\n",
    "team_ids = pd.unique(tour_ratios.loc[tour_ratios[\"Season\"] == 2015, [\"WTeamID\", \"LTeamID\"]].values.ravel('K'))\n",
    "tour_avgs = pd.DataFrame(index=range(team_ids.shape[0]), columns=tour_avg_cols)\n",
    "tour_avgs.loc[:,\"TeamID\"] = team_ids\n",
    "# print(test_x)\n",
    "\n",
    "for team_id in team_ids:\n",
    "    games_all = reg_ratios.loc[(reg_ratios[\"WTeamID\"] == team_id) | (reg_ratios[\"LTeamID\"] == team_id)]\n",
    "    games = games_all.loc[games_all[\"Season\"] == 2015]\n",
    "    games.reset_index(inplace=True, drop=True)\n",
    "    games_stats = games.loc[:, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\",\"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]]\n",
    "    for i, row in games.iterrows():\n",
    "        if ((team_id == row[\"WTeamID\"]) & (row[\"NumTeamWon\"] == 0)) | ((team_id == row[\"LTeamID\"]) & (row[\"NumTeamWon\"] == 1)):\n",
    "            games_stats.iloc[i] = games_stats.iloc[i].apply(np.reciprocal)\n",
    "#             if math.isinf(games_stats.at[i,\"Loc\"]):\n",
    "#                 games_stats.loc[i,\"Loc\"] = 0\n",
    "    \n",
    "    tour_avgs.loc[tour_avgs[\"TeamID\"] == team_id, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]] = games_stats.mean(axis=0).ravel()\n",
    "    \n",
    "tour_avgs = tour_avgs.set_index(\"TeamID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test_x_columns = [item for item in all_cols if item not in cols_to_drop]\n",
    "# print(test_x_columns)\n",
    "\n",
    "tourney_games_2017 = tour_ratios.loc[tour_ratios[\"Season\"] == 2015]\n",
    "tourney_games_2017 = tourney_games_2017.reset_index(drop=True)\n",
    "# print(tourney_games_2017.shape)\n",
    "test_x = pd.DataFrame(index=range(tourney_games_2017.shape[0]), columns=test_x_columns)\n",
    "test_y = np.ones(67)\n",
    "for i, row in tourney_games_2017.iterrows():\n",
    "    teamA_id = tourney_games_2017.at[i, \"WTeamID\"]\n",
    "    teamB_id = tourney_games_2017.at[i, \"LTeamID\"]\n",
    "    teamA_stats = tour_avgs.loc[teamA_id, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]].as_matrix()\n",
    "    teamB_stats = tour_avgs.loc[teamB_id, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]].as_matrix()\n",
    "    r = random.random()\n",
    "    if r > 0.5:\n",
    "#         test_x[\"WTeamID\"] = teamA_id\n",
    "#         test_x[\"LTeamID\"] = teamB_id\n",
    "#         test_x[\"Loc\"] = 0\n",
    "        test_x.loc[i, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]] = teamA_stats / teamB_stats\n",
    "    else:\n",
    "#         test_x[\"WTeamID\"] = teamB_id\n",
    "#         test_x[\"LTeamID\"] = teamA_id\n",
    "#         test_x[\"Loc\"] = 0\n",
    "        test_x.loc[i, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"DRR\", \"AstR\",\n",
    "                                           \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]] = teamB_stats / teamA_stats\n",
    "        test_y[i] = 0\n",
    "    \n",
    "# print(test_x)\n",
    "test_x = test_x.as_matrix()\n",
    "# print(train_x.shape)\n",
    "# print(train_y.shape)\n",
    "# print(test_x.shape)\n",
    "# print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oob score: {} 0.6453949771307421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# num_splits = 10\n",
    "# ll_best = 1000\n",
    "# num_features_best = 1\n",
    "# kf = KFold(n_splits=num_splits)\n",
    "# for num_features_to_use in range(1, 17):\n",
    "#     ll_feature_count = 0\n",
    "#     for train, test in kf.split(train_x):\n",
    "#         clf2 = RandomForestRegressor(n_estimators=5000, oob_score=True, max_features=num_features_to_use)\n",
    "#         clf2.fit(train_x[train], train_y[train].ravel())\n",
    "#         preds = clf2.predict(train_x[test])\n",
    "#         ll_feature_count = log_loss(train_y[test], preds) / num_splits\n",
    "    \n",
    "#     if ll_feature_count < ll_best:\n",
    "#         ll_best = ll_feature_count\n",
    "#         num_features_best = num_features_to_use\n",
    "\n",
    "# print(\"Best number of features to use: {}\", num_features_best)\n",
    "# print(\"Log loss achieved: {}\", ll_best)\n",
    "\n",
    "clf2 = RandomForestRegressor(n_estimators=5000, oob_score=True, max_features=1, min_samples_leaf=50, n_jobs=-1)\n",
    "clf2.fit(train_x, train_y.ravel())\n",
    "print(\"oob score: {}\", clf2.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.6567164179104478\n",
      "[0.47863992 0.47879407 0.41359583 0.35734047 0.11151679 0.67420572\n",
      " 0.37970829 0.69398893 0.23691362 0.46557591 0.97399429 0.74747724\n",
      " 0.45531481 0.80893795 0.13674792 0.83549993 0.13623675 0.23046119\n",
      " 0.91457332 0.35474287 0.59600911 0.91891554 0.85321546 0.59153471\n",
      " 0.14799383 0.2170854  0.52099991 0.38951794 0.73481686 0.3446836\n",
      " 0.43025277 0.81357031 0.0988598  0.55123117 0.24131607 0.9113362\n",
      " 0.24764183 0.92735045 0.89694036 0.45069965 0.1774557  0.53671202\n",
      " 0.87588841 0.50815789 0.37358878 0.81916046 0.25653359 0.85766557\n",
      " 0.45654112 0.62090609 0.73852116 0.90009723 0.1147239  0.05985707\n",
      " 0.38963418 0.22175865 0.50873776 0.0672134  0.81816814 0.42214715\n",
      " 0.88815987 0.34443636 0.50465374 0.54312394 0.23009355 0.25914111\n",
      " 0.27536869]\n",
      "[1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1.]\n",
      "Log loss 0.5957238434983908\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds = clf2.predict(test_x)\n",
    "print(\"Accuracy score\", accuracy_score(test_y, preds > 0.5))\n",
    "print(preds)\n",
    "print(test_y)\n",
    "print(\"Log loss\", log_loss(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGMR : 0.19460037000804545\n",
      "FGAR : 0.021075793072354257\n",
      "FGMR3 : 0.04536180274748659\n",
      "FGAR3 : 0.01592329594439309\n",
      "FTMR : 0.1181382775296927\n",
      "FTAR : 0.0944975126589396\n",
      "DRR : 0.17348269414637926\n",
      "AstR : 0.1354413605094929\n",
      "TOR : 0.04546660630848851\n",
      "StlR : 0.034265551128565955\n",
      "BlkR : 0.0381803263480402\n",
      "PFR : 0.08356640959812202\n"
     ]
    }
   ],
   "source": [
    "variables = test_x_columns\n",
    "feature_importance = clf2.feature_importances_\n",
    "for i in range(len(feature_importance)):\n",
    "    print(variables[i], \":\", feature_importance[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WTeamID', 'LTeamID', 'FGMR', 'FGAR', 'FGMR3', 'FGAR3', 'FTMR', 'FTAR', 'ORR', 'DRR', 'AstR', 'TOR', 'StlR', 'BlkR', 'PFR']\n"
     ]
    }
   ],
   "source": [
    "print(test_x_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
