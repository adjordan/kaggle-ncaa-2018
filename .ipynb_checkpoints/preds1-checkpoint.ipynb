{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season TeamID      FGMR      FGAR     FGMR3     FGAR3      FTMR      FTAR  \\\n",
      "0    2017   1243   1.10154  0.981988   1.05094   1.09203   1.36656   1.36491   \n",
      "1    2017   1291  0.986222  0.979794   1.77279   1.37903   1.16017   1.06083   \n",
      "2    2017   1413   1.00627  0.988064   1.10613  0.895115   1.47796   1.83711   \n",
      "3    2017   1425   1.03186  0.957951   1.11822   1.01172   2.05628   1.86904   \n",
      "4    2017   1112   1.12224  0.971343   1.27608  0.857243   1.91802   1.57692   \n",
      "5    2017   1139   1.15861   1.05787   1.27133     1.075   1.12676   1.04409   \n",
      "6    2017   1196   1.16118   1.03256   1.84946   1.22727   1.45438   1.34282   \n",
      "7    2017   1199   1.26253   1.05627   1.17845  0.958448   1.21959   1.21378   \n",
      "8    2017   1211   1.39475  0.968298   1.68969   1.09368   1.89001   1.59918   \n",
      "9    2017   1235   1.14461   1.01789   1.60363   1.20148   1.46309    1.3124   \n",
      "10   2017   1292   1.31531   1.11538   1.37128   1.09106  0.950387   0.96748   \n",
      "11   2017   1321   1.13904   1.03789    1.4507   1.13273   1.15077   1.01549   \n",
      "12   2017   1323   1.12384   1.02103    1.5299   1.26257   1.32155   1.19185   \n",
      "13   2017   1345    1.1305  0.952356   1.78608    1.1518   2.52796   2.25681   \n",
      "14   2017   1388   1.30198   1.02243   2.56924   1.72744   1.70537   1.35118   \n",
      "15   2017   1437   1.17224  0.966048   1.39984   1.10072   2.32277   1.96669   \n",
      "16   2017   1438   1.40516   1.12263   1.30738  0.985124   1.08736  0.997782   \n",
      "17   2017   1452   1.35618   1.21257   1.31271   1.17254    1.3065   1.22025   \n",
      "18   2017   1458   1.23746   1.08602   1.29064   1.25079   1.83536   1.61792   \n",
      "19   2017   1462   1.06014   1.02032   1.12092   0.98785    1.3595   1.35935   \n",
      "20   2017   1116   1.14482   1.02487   1.01831  0.836817   1.26323   1.12019   \n",
      "21   2017   1124   1.17682  0.998968   1.27169   1.01215   1.61636   1.82381   \n",
      "22   2017   1153   1.31484   1.09693   1.36688   1.15646   1.23429   1.29746   \n",
      "23   2017   1181   1.11921  0.979943   2.22109   1.44583   1.60727   1.39598   \n",
      "24   2017   1242   1.17241  0.997845   1.50323   1.17317   1.30038   1.37905   \n",
      "25   2017   1246   1.20939   1.05063   1.30521   1.10072    1.5941   1.40842   \n",
      "26   2017   1257   1.30723   1.10076   1.55145    1.1085   1.08579   1.04484   \n",
      "27   2017   1276   1.08531   1.02434   1.91231   1.66692   1.69828   1.41098   \n",
      "28   2017   1277   1.12637  0.955557   1.40147   1.19922  0.965416   1.00053   \n",
      "29   2017   1314     1.288   1.12833   1.03443  0.893421   1.64306   1.47484   \n",
      "..    ...    ...       ...       ...       ...       ...       ...       ...   \n",
      "38   2017   1344   1.01939  0.986474   1.54681   1.38708   1.51206   1.38572   \n",
      "39   2017   1315   1.12036   1.02016   1.51768   1.01767   1.20722   1.08915   \n",
      "40   2017   1457   1.09614  0.976979   1.95135   1.31525   1.33304   1.32549   \n",
      "41   2017   1190   1.21016   1.00833   1.07487  0.933519   1.22919   1.26538   \n",
      "42   2017   1195   1.16387   1.01547   1.18679  0.887823   1.33586   1.07592   \n",
      "43   2017   1355  0.920321  0.911503  0.992119   1.00005   1.75884   1.58397   \n",
      "44   2017   1305    1.0379  0.970218   1.78373   1.17914   1.90987   1.81982   \n",
      "45   2017   1278   1.05501  0.963321    1.3012  0.911359    1.5452    1.4192   \n",
      "46   2017   1435  0.995589  0.943518   2.20338   1.54122   1.38998     1.294   \n",
      "47   2017   1343   1.18324   1.10017   1.86794    1.4189   1.10294   1.02847   \n",
      "48   2017   1436   1.19343   1.00699   1.54781     1.113   1.81394   1.60774   \n",
      "49   2017   1433   1.21879   1.07687   1.30363   1.14757   1.09853   1.05652   \n",
      "50   2017   1423   1.14869   1.15597   2.13402   2.47453  0.983795  0.948808   \n",
      "51   2017   1137   1.12935   0.98062   1.54822   1.28642     1.367   1.24624   \n",
      "52   2017   1439   1.00504  0.902156    1.2484   1.06951   1.82757   1.58869   \n",
      "53   2017   1268   1.04611   0.95544   1.57476   1.25529   1.43049   1.41442   \n",
      "54   2017   1371   1.10084   1.04554   1.18141    1.0054   1.02971   1.14651   \n",
      "55   2017   1308   1.09764  0.995632   1.71536   1.23117   1.54072   1.39709   \n",
      "56   2017   1407   1.03126  0.988018   1.27131   1.09296   1.38586    1.3469   \n",
      "57   2017   1297   1.00578  0.967536   1.63349   1.28334   1.36024   1.33418   \n",
      "58   2017   1240   1.08249  0.985174   1.11083   1.04451   1.03378   1.03833   \n",
      "59   2017   1329   1.13557   1.11146   1.64316   1.32894   1.12915  0.965005   \n",
      "60   2017   1274   1.11356   1.00354   1.18325   1.01076   1.82089   1.71451   \n",
      "61   2017   1411  0.994531   0.97256   1.41196   1.19287   1.67647   1.43111   \n",
      "62   2017   1233   1.06463   1.00392   1.56637   1.26768    1.1226   1.02685   \n",
      "63   2017   1166   1.17545   1.00014   1.43604   1.04859   1.21697   1.15689   \n",
      "64   2017   1266   1.13344   1.02633   1.78167   1.30192   1.04227  0.951635   \n",
      "65   2017   1245   1.07612   1.08604    1.1046   1.13517   1.45645   1.29055   \n",
      "66   2017   1374   1.26341   1.00768   1.20948  0.831422   1.82554    1.7142   \n",
      "67   2017   1173    1.1383  0.992269   1.42127  0.989734   1.36252   1.35884   \n",
      "\n",
      "         ORR       DRR      AstR       TOR      StlR      BlkR       PFR  \n",
      "0   0.964283   1.06004   1.22969  0.905726   1.47353    1.8097  0.928655  \n",
      "1    0.73223  0.925564   1.19308  0.924525   1.08979   2.32937  0.982755  \n",
      "2    1.20991    1.0728   1.00193   1.07088   1.00143   1.31219  0.943476  \n",
      "3   0.999329   1.07855   1.12634  0.964047   1.57726    2.7039  0.868465  \n",
      "4    1.39192   1.33351   1.15939   1.02125   1.45663   1.77395   0.88726  \n",
      "5    1.27749   1.06787   1.55576  0.778545   1.41764   1.60286   1.02693  \n",
      "6    1.19477   1.08683   1.60988  0.836646   2.00043   2.44777  0.911767  \n",
      "7    1.25965   1.19901   1.37873  0.855341   1.94145     2.557   1.03382  \n",
      "8    1.33703   1.44143   1.83938   1.01242   1.61497    2.7251  0.867261  \n",
      "9   0.873963   1.00598   1.28613  0.786345   2.16408   1.50028  0.998157  \n",
      "10   1.53832   1.18841   1.52254   0.81913   2.26985   1.61818   1.17659  \n",
      "11   1.03154   1.11787   1.34928   0.98862  0.983257   1.63323   1.11072  \n",
      "12  0.952229   1.02892   1.41595  0.803245    1.8116   1.55362  0.993231  \n",
      "13   1.24695   1.34781   1.60953   1.20285  0.926255    1.3211   0.85371  \n",
      "14   1.90106   1.43833   2.26482   1.23569  0.984391   2.11325   1.01231  \n",
      "15   1.13888   1.26515   1.14826  0.882299   1.76683   2.08367  0.793968  \n",
      "16   1.48038   1.18323   1.80405   0.83053    1.5913   2.00115   1.17912  \n",
      "17   1.43986   0.99034   1.47951  0.673118   2.46165   1.93437  0.995196  \n",
      "18   2.28623   1.18403   1.56945  0.930704   1.68434   1.63406  0.881607  \n",
      "19   2.00892   1.15935   1.15337   1.14179   1.58632   0.96538  0.906716  \n",
      "20   1.04664   1.09386   1.20186   0.96185   1.90558   2.11828   1.12375  \n",
      "21   1.49095   1.35228    1.2894   1.38841   1.41553    2.4205   1.02338  \n",
      "22   1.38353   1.16234   1.54952  0.786214   2.64962   2.46421  0.989975  \n",
      "23   1.17392   1.21142   1.21324   1.08138   1.41453   2.66626   0.92529  \n",
      "24   1.13196   1.23397    1.3808   1.04192   1.13509   1.77452  0.974083  \n",
      "25   1.47765    1.1729   1.57509  0.921613   1.77094   2.75926  0.852274  \n",
      "26   1.38035   1.17182   1.42495  0.857144   1.70673   2.31709   1.06896  \n",
      "27   1.03048   1.01138   1.33596  0.769735   1.98718   1.62902  0.895093  \n",
      "28   1.07959   1.25455    1.4781   1.40478  0.937801   2.10076    1.1374  \n",
      "29   1.99145   1.30444   1.73387  0.981546   1.36374  0.852877   0.95987  \n",
      "..       ...       ...       ...       ...       ...       ...       ...  \n",
      "38   1.16822   1.00599   1.41325  0.973108   1.17537   1.42141   0.90635  \n",
      "39    0.9951   1.07404   1.49931  0.994272   1.44633   1.60482   1.10654  \n",
      "40   1.05408    1.0956    1.5487  0.990807   1.37233   2.18067   0.94149  \n",
      "41   1.16478   1.20118    1.4477   1.01201   1.39604   2.15754   1.00769  \n",
      "42   1.16633   1.23095   1.28582   1.11911   1.14188    1.8453   1.08829  \n",
      "43   1.00121   1.12187  0.986109   1.23524    1.0553   1.11945  0.841225  \n",
      "44    1.2186   1.15029   1.26081   1.11406   1.22403   2.70677   0.83214  \n",
      "45   1.21201   1.10657   1.19153  0.979803   1.32398   2.49806    0.8577  \n",
      "46   1.09091   1.11561   1.41226   1.24151  0.987277   1.78684   1.04872  \n",
      "47   1.29888   1.03733   1.39369  0.823311   1.72475   1.83721   1.08372  \n",
      "48   1.25153   1.18573   1.51844    0.9407   1.35168   2.55326  0.880018  \n",
      "49     1.288   1.09708   1.65225  0.882143   1.63531   1.71959   1.06279  \n",
      "50   1.47255  0.961856   1.33994  0.709947   2.38392   1.94833   1.09685  \n",
      "51  0.983758   1.14711   1.34887   1.00969    1.1769   1.75369  0.993317  \n",
      "52  0.833937    1.0906   1.24143   1.11587   1.05294   1.00577  0.870498  \n",
      "53    1.0379   1.09285   1.36292   1.09899   1.16809   1.88703  0.996573  \n",
      "54   1.62262   1.14646   1.13789   1.16402   1.25155   1.21046  0.996983  \n",
      "55   1.45131   1.25695   1.51179   1.06914   1.20672   2.45656  0.892827  \n",
      "56   1.10938   1.07126    1.1694   1.12134   1.43425   1.68178  0.954202  \n",
      "57   1.32669    1.1301    1.2854   1.23374   1.16582   1.08125  0.993446  \n",
      "58   1.39939   1.19903   1.40368   1.35518  0.980556   2.29087   1.06521  \n",
      "59   1.39744   1.10999    1.2303  0.970324    1.8641  0.928454   1.12012  \n",
      "60   1.47123   1.19179   1.13365   1.13864   1.37092   2.22003  0.987927  \n",
      "61   1.07747   1.01751   1.11792  0.990767   1.95083   1.49022  0.833066  \n",
      "62  0.912209   1.04064   1.14426  0.997293   1.88724   1.47591   1.15072  \n",
      "63  0.809944   1.08835   1.42509  0.925489   1.25016   1.25259  0.986168  \n",
      "64  0.973128   1.07751   1.11428   1.00147   1.33187    1.4182   1.16133  \n",
      "65   1.59881   1.11498   1.02003  0.970049    1.5569   2.25297   1.01754  \n",
      "66   1.66168   1.38233   1.48738   1.03671   1.81459    1.9052  0.814629  \n",
      "67   1.12092   1.09032   1.36316  0.859058   2.03766   1.67983  0.958436  \n",
      "\n",
      "[68 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import relevant data files\n",
    "reg_ratios = pd.read_csv(\"RegularSeasonDetailedResultsRatios.csv\")\n",
    "tour_ratios = pd.read_csv(\"NCAATourneyDetailedResultsRatios.csv\")\n",
    "\n",
    "# List of all columns in the datasets\n",
    "# all_cols = reg_ratios.columns.tolist()\n",
    "all_cols = [\"Season\", \"WTeamID\", \"WScore\", \"LTeamID\", \"LScore\", \"NumTeamWon\", \"Loc\",\n",
    "                 \"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"ORR\", \"DRR\", \"AstR\",\n",
    "                 \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]\n",
    "\n",
    "# Columns that won't be used in the dataset\n",
    "cols_to_drop = [\"Season\", \"WTeamID\", \"WScore\", \"LTeamID\", \"LScore\", \"NumTeamWon\", \"Loc\"]\n",
    "\n",
    "# Columns that will be used in the dataset\n",
    "stats_columns = [item for item in all_cols if item not in cols_to_drop]\n",
    "\n",
    "# Years to look at\n",
    "seasons = [2017]\n",
    "\n",
    "# Specify what to use as the training data\n",
    "train_data = reg_ratios\n",
    "\n",
    "# Get all of the training data for the given years\n",
    "train_x = reg_ratios.loc[reg_ratios[\"Season\"].isin(seasons)].drop(labels=cols_to_drop, axis=1).as_matrix()\n",
    "train_y = reg_ratios.loc[reg_ratios[\"Season\"].isin(seasons)][\"NumTeamWon\"].as_matrix()\n",
    "\n",
    "# Get all team IDs from the tournament\n",
    "reg_season_avg_cols = [\"Season\", \"TeamID\"] + stats_columns\n",
    "\n",
    "# Create a dataframe with teamIDs for all tourneys with season in which that team played\n",
    "team_ids = pd.DataFrame(index=range(len(seasons)*68), columns=[\"Season\", \"TeamID\"])\n",
    "for season in seasons:\n",
    "    team_ids_for_season = pd.unique(tour_ratios.loc[tour_ratios[\"Season\"] == 2017, [\"WTeamID\", \"LTeamID\"]].values.ravel('K'))\n",
    "    for i in range(len(team_ids_for_season)):\n",
    "        team_ids.loc[i, \"Season\"] = season\n",
    "        team_ids.loc[i, \"TeamID\"] = team_ids_for_season[i]\n",
    "\n",
    "# Create a data sets to hold regular season averages for every team in the tournament for every specified year\n",
    "reg_season_avgs = pd.DataFrame(index=range(team_ids.shape[0]), columns=reg_season_avg_cols)\n",
    "reg_season_avgs[\"Season\"] = team_ids[\"Season\"]\n",
    "reg_season_avgs[\"TeamID\"] = team_ids[\"TeamID\"]\n",
    "\n",
    "for season in seasons:\n",
    "    team_ids_for_season = reg_season_avgs.loc[reg_season_avgs[\"Season\"] == season, \"TeamID\"].tolist()\n",
    "        \n",
    "    for team_id in team_ids_for_season:\n",
    "        games_all = reg_ratios.loc[(reg_ratios[\"WTeamID\"] == team_id) | (reg_ratios[\"LTeamID\"] == team_id)]\n",
    "        games = games_all.loc[games_all[\"Season\"] == season]\n",
    "        games.reset_index(inplace=True, drop=True)\n",
    "        games_stats = games.loc[:, stats_columns]\n",
    "        for i, row in games.iterrows():\n",
    "            if ((team_id == row[\"WTeamID\"]) & (row[\"NumTeamWon\"] == 0)) | ((team_id == row[\"LTeamID\"]) & (row[\"NumTeamWon\"] == 1)):\n",
    "                games_stats.iloc[i] = games_stats.iloc[i].apply(np.reciprocal)\n",
    "    \n",
    "        reg_season_avgs.loc[(reg_season_avgs[\"TeamID\"] == team_id) & (reg_season_avgs[\"Season\"] == season), stats_columns] = games_stats.mean(axis=0).ravel()\n",
    "\n",
    "print(reg_season_avgs)\n",
    "# reg_season_avgs = reg_season_avgs.set_index(\"TeamID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the label [1243] is not in the [index]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m                     \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1500\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1501\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [1243] is not in the [index]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8ac3198d8897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mteamB_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtourney_games_2017\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LTeamID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     teamA_stats = tour_avgs.loc[teamA_id, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"DRR\", \"AstR\",\n\u001b[0;32m---> 10\u001b[0;31m                                            \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]].as_matrix()\n\u001b[0m\u001b[1;32m     11\u001b[0m     teamB_stats = tour_avgs.loc[teamB_id, [\"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"DRR\", \"AstR\",\n\u001b[1;32m     12\u001b[0m                                            \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]].as_matrix()\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m                 \u001b[0;31m# we have yielded a scalar ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1512\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m                 \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 raise KeyError(u\"the label [{key}] is not in the [{axis}]\"\n\u001b[1;32m   1500\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1501\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [1243] is not in the [index]'"
     ]
    }
   ],
   "source": [
    "tourney_games = tour_ratios.loc[tour_ratios[\"Season\"].isin(years)]\n",
    "tourney_games = tourney_games.reset_index(drop=True)\n",
    "# print(tourney_games_2017.shape)\n",
    "test_x = pd.DataFrame(index=range(tourney_games_2017.shape[0]), columns=stats_columns)\n",
    "test_y = np.ones(67*len(seasons))\n",
    "for i in len(seasons):\n",
    "    season = seasons[i]\n",
    "    tourney_games_for_season = tourney_games.loc[reg_season_avgs[\"Season\"] == season]\n",
    "    for j, row in tourney_games_for_season.iterrows():\n",
    "        index = i * 67 + j\n",
    "        teamA_id = tourney_games_for_season.at[i, \"WTeamID\"]\n",
    "        teamB_id = tourney_games_for_season.at[i, \"LTeamID\"]\n",
    "        teamA_stats = reg_season_avgs.loc[(reg_season_avgs[\"TeamID\"] == teamA_id) & (reg_season_avgs[\"Season\"] == season), stats_columns].as_matrix()\n",
    "        teamB_stats = reg_season_avgs.loc[(reg_season_avgs[\"TeamID\"] == teamB_id) & (reg_season_avgs[\"Season\"] == season), stats_columns].as_matrix()\n",
    "        r = random.random()\n",
    "        if r > 0.5:\n",
    "    #         test_x[\"WTeamID\"] = teamA_id\n",
    "    #         test_x[\"LTeamID\"] = teamB_id\n",
    "    #         test_x[\"Loc\"] = 0\n",
    "            test_x.loc[index, stats_columns] = teamA_stats / teamB_stats\n",
    "        else:\n",
    "            test_x.loc[index, stats_columns] = teamB_stats / teamA_stats\n",
    "            test_y[i] = 0\n",
    "    \n",
    "# print(test_x)\n",
    "test_x = test_x.as_matrix()\n",
    "# print(train_x.shape)\n",
    "# print(train_y.shape)\n",
    "# print(test_x.shape)\n",
    "# print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oob score: {} 0.8458122286358658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss, mean_squared_error\n",
    "\n",
    "# num_splits = 10\n",
    "# ll_best = 1000\n",
    "# num_features_best = 1\n",
    "# kf = KFold(n_splits=num_splits)\n",
    "# for num_features_to_use in range(1, 17):\n",
    "#     ll_feature_count = 0\n",
    "#     for train, test in kf.split(train_x):\n",
    "#         clf2 = RandomForestRegressor(n_estimators=5000, oob_score=True, max_features=num_features_to_use)\n",
    "#         clf2.fit(train_x[train], train_y[train].ravel())\n",
    "#         preds = clf2.predict(train_x[test])\n",
    "#         ll_feature_count = log_loss(train_y[test], preds) / num_splits\n",
    "    \n",
    "#     if ll_feature_count < ll_best:\n",
    "#         ll_best = ll_feature_count\n",
    "#         num_features_best = num_features_to_use\n",
    "\n",
    "# print(\"Best number of features to use: {}\", num_features_best)\n",
    "# print(\"Log loss achieved: {}\", ll_best)\n",
    "\n",
    "clf2 = RandomForestRegressor(n_estimators=5000, oob_score=True, max_features=4, min_samples_leaf=1, n_jobs=-1)\n",
    "clf2.fit(train_x, train_y.ravel())\n",
    "print(\"oob score: {}\", clf2.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 13 and input n_features is 12 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0674a4c0688d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Log Loss, Train: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Log Loss, Test: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    355\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    382\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 13 and input n_features is 12 "
     ]
    }
   ],
   "source": [
    "preds_train = clf2.predict(train_x)\n",
    "preds_test = clf2.predict(test_x)\n",
    "\n",
    "print(\"Log Loss, Train: \", log_loss(train_y, preds_train))\n",
    "print(\"Log Loss, Test: \", log_loss(test_y, preds_test))\n",
    "print(\"\")\n",
    "print(\"Accuracy, Train\", accuracy_score(train_y, preds_train > 0.5))\n",
    "print(\"Accuracy, Test\", accuracy_score(test_y, preds_test > 0.5))\n",
    "# print(preds_test)\n",
    "# print(test_y)\n",
    "# print(\"Log loss\", log_loss(test_y, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGMR : 0.2661684289801305\n",
      "FGAR : 0.017757013767729524\n",
      "FGMR3 : 0.051357716289353525\n",
      "FGAR3 : 0.016470414111656125\n",
      "FTMR : 0.15362692111669005\n",
      "FTAR : 0.08434325049422604\n",
      "DRR : 0.1587136196251818\n",
      "AstR : 0.09986918935151781\n",
      "TOR : 0.061197488980729804\n",
      "StlR : 0.02103141677041243\n",
      "BlkR : 0.013251364547296196\n",
      "PFR : 0.056213175965077314\n"
     ]
    }
   ],
   "source": [
    "variables = test_x_columns\n",
    "feature_importance = clf2.feature_importances_\n",
    "for i in range(len(feature_importance)):\n",
    "    print(variables[i], \":\", feature_importance[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FGMR', 'FGAR', 'FGMR3', 'FGAR3', 'FTMR', 'FTAR', 'DRR', 'AstR', 'TOR', 'StlR', 'BlkR', 'PFR']\n"
     ]
    }
   ],
   "source": [
    "print(test_x_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
