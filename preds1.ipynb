{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant data files\n",
    "reg_ratios = pd.read_csv(\"RegularSeasonDetailedResultsRatios.csv\")\n",
    "tour_ratios = pd.read_csv(\"NCAATourneyDetailedResultsRatios.csv\")\n",
    "\n",
    "# List of all columns in the datasets\n",
    "# all_cols = reg_ratios.columns.tolist()\n",
    "all_cols = [\"Season\", \"WTeamID\", \"WScore\", \"LTeamID\", \"LScore\", \"NumTeamWon\", \"Loc\",\n",
    "                 \"FGMR\", \"FGAR\", \"FGMR3\", \"FGAR3\", \"FTMR\", \"FTAR\", \"ORR\", \"DRR\", \"AstR\",\n",
    "                 \"TOR\", \"StlR\", \"BlkR\", \"PFR\"]\n",
    "\n",
    "# Columns that won't be used in the dataset\n",
    "cols_to_drop = [\"Season\", \"WTeamID\", \"WScore\", \"LTeamID\", \"LScore\", \"NumTeamWon\", \"Loc\"]\n",
    "\n",
    "# Columns that will be used in the dataset\n",
    "stats_columns = [item for item in all_cols if item not in cols_to_drop]\n",
    "\n",
    "# Years to look at\n",
    "seasons = [2017]\n",
    "\n",
    "# Specify what to use as the training data\n",
    "train_data = reg_ratios\n",
    "\n",
    "# Get all of the training data for the given years\n",
    "train_x = reg_ratios.loc[reg_ratios[\"Season\"].isin(seasons)].drop(labels=cols_to_drop, axis=1).as_matrix()\n",
    "train_y = reg_ratios.loc[reg_ratios[\"Season\"].isin(seasons)][\"NumTeamWon\"].as_matrix()\n",
    "\n",
    "# Get all team IDs from the tournament\n",
    "reg_season_avg_cols = [\"Season\", \"TeamID\"] + stats_columns\n",
    "\n",
    "# Create a dataframe with teamIDs for all tourneys with season in which that team played\n",
    "team_ids = pd.DataFrame(index=range(len(seasons)*68), columns=[\"Season\", \"TeamID\"])\n",
    "for season in seasons:\n",
    "    team_ids_for_season = pd.unique(tour_ratios.loc[tour_ratios[\"Season\"] == 2017, [\"WTeamID\", \"LTeamID\"]].values.ravel('K'))\n",
    "    for i in range(len(team_ids_for_season)):\n",
    "        team_ids.loc[i, \"Season\"] = season\n",
    "        team_ids.loc[i, \"TeamID\"] = team_ids_for_season[i]\n",
    "\n",
    "# Create a data sets to hold regular season averages for every team in the tournament for every specified year\n",
    "reg_season_avgs = pd.DataFrame(index=range(team_ids.shape[0]), columns=reg_season_avg_cols)\n",
    "reg_season_avgs[\"Season\"] = team_ids[\"Season\"]\n",
    "reg_season_avgs[\"TeamID\"] = team_ids[\"TeamID\"]\n",
    "\n",
    "for season in seasons:\n",
    "    team_ids_for_season = reg_season_avgs.loc[reg_season_avgs[\"Season\"] == season, \"TeamID\"].tolist()\n",
    "        \n",
    "    for team_id in team_ids_for_season:\n",
    "        games_all = reg_ratios.loc[(reg_ratios[\"WTeamID\"] == team_id) | (reg_ratios[\"LTeamID\"] == team_id)]\n",
    "        games = games_all.loc[games_all[\"Season\"] == season]\n",
    "        games.reset_index(inplace=True, drop=True)\n",
    "        games_stats = games.loc[:, stats_columns]\n",
    "        for i, row in games.iterrows():\n",
    "            if ((team_id == row[\"WTeamID\"]) & (row[\"NumTeamWon\"] == 0)) | ((team_id == row[\"LTeamID\"]) & (row[\"NumTeamWon\"] == 1)):\n",
    "                games_stats.iloc[i] = games_stats.iloc[i].apply(np.reciprocal)\n",
    "    \n",
    "        reg_season_avgs.loc[(reg_season_avgs[\"TeamID\"] == team_id) & (reg_season_avgs[\"Season\"] == season), stats_columns] = games_stats.mean(axis=0).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X:  (5395, 13)\n",
      "Train Y:  (5395,)\n",
      "Test X:   (67, 13)\n",
      "Test Y:   (67,)\n"
     ]
    }
   ],
   "source": [
    "tourney_games = tour_ratios.loc[tour_ratios[\"Season\"].isin(seasons)]\n",
    "tourney_games = tourney_games.reset_index(drop=True)\n",
    "\n",
    "test_x = pd.DataFrame(index=range(tourney_games.shape[0]), columns=stats_columns)\n",
    "test_y = np.ones(67*len(seasons))\n",
    "for i in range(len(seasons)):\n",
    "    season = seasons[i]\n",
    "    tourney_games_for_season = tourney_games.loc[tourney_games[\"Season\"] == season]\n",
    "    for j, row in tourney_games_for_season.iterrows():\n",
    "        index = i * 67 + j\n",
    "        teamA_id = tourney_games_for_season.at[j, \"WTeamID\"]\n",
    "        teamB_id = tourney_games_for_season.at[j, \"LTeamID\"]\n",
    "        teamA_stats = reg_season_avgs.loc[(reg_season_avgs[\"TeamID\"] == teamA_id) & (reg_season_avgs[\"Season\"] == season), stats_columns].as_matrix()\n",
    "        teamB_stats = reg_season_avgs.loc[(reg_season_avgs[\"TeamID\"] == teamB_id) & (reg_season_avgs[\"Season\"] == season), stats_columns].as_matrix()\n",
    "        r = random.random()\n",
    "        if r > 0.5:\n",
    "            test_x.loc[index, stats_columns] = teamA_stats / teamB_stats\n",
    "        else:\n",
    "            test_x.loc[index, stats_columns] = teamB_stats / teamA_stats\n",
    "            test_y[i] = 0\n",
    "    \n",
    "test_x = test_x.as_matrix()\n",
    "print(\"Train X: \", train_x.shape)\n",
    "print(\"Train Y: \", train_y.shape)\n",
    "print(\"Test X:  \", test_x.shape)\n",
    "print(\"Test Y:  \", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=13, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=5000, n_jobs=-1, oob_score=False,\n",
       "           random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestRegressor(n_estimators=5000, oob_score=False, max_features=13, min_samples_leaf=1, n_jobs=-1)\n",
    "clf.fit(train_x, train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, Train:  1.0\n",
      "Log Loss, Train:  0.03891280353281886\n",
      "\n",
      "Accuracy, Test:   0.5373134328358209\n",
      "Log Loss, Test:   2.4164428884452827\n"
     ]
    }
   ],
   "source": [
    "preds_train = clf.predict(train_x)\n",
    "preds_test = clf.predict(test_x)\n",
    "\n",
    "print(\"Accuracy, Train: \", accuracy_score(train_y, preds_train > 0.5))\n",
    "print(\"Log Loss, Train: \", log_loss(train_y, preds_train))\n",
    "print(\"\")\n",
    "print(\"Accuracy, Test:  \", accuracy_score(test_y, preds_test > 0.5))\n",
    "print(\"Log Loss, Test:  \", log_loss(test_y, preds_test))\n",
    "# print(preds_test)\n",
    "# print(test_y)\n",
    "# print(\"Log loss\", log_loss(test_y, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGMR : 0.1783877774182809\n",
      "FGAR : 0.03968620367167515\n",
      "FGMR3 : 0.06566348229014081\n",
      "FGAR3 : 0.036065276620378374\n",
      "FTMR : 0.09261160782621278\n",
      "FTAR : 0.07877265493266138\n",
      "ORR : 0.030477507521364657\n",
      "DRR : 0.15220920420422562\n",
      "AstR : 0.11361003322119814\n",
      "TOR : 0.05383051098203282\n",
      "StlR : 0.04349486108293387\n",
      "BlkR : 0.0437610144163479\n",
      "PFR : 0.07142986581254765\n"
     ]
    }
   ],
   "source": [
    "variables = stats_columns\n",
    "feature_importance = clf.feature_importances_\n",
    "for i in range(len(feature_importance)):\n",
    "    print(variables[i], \":\", feature_importance[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
